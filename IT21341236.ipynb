{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b8d0b2a-b16e-42e4-82cb-33b57d086ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1), y_train shape: (60000, 10)\n",
      "x_test shape: (10000, 28, 28, 1), y_test shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import pickle\n",
    "\n",
    "# Load the Fashion MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Normalize the pixel values (0-255) to (0-1)\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Reshape the data to add a channel dimension (1 channel for grayscale images)\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "\n",
    "# One-hot encoding for labels (10 classes for Fashion MNIST)\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "# Save the preprocessed data using pickle for later use\n",
    "with open('fashion_mnist_preprocessed.pkl', 'wb') as f:\n",
    "    pickle.dump((x_train, y_train, x_test, y_test), f)\n",
    "\n",
    "# Print the shape of the dataset\n",
    "print(f\"x_train shape: {x_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape}, y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f0cd809-4bb2-4672-8abd-bb9b1e24df9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahub\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m320\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m36,928\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m4,160\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m650\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">60,554</span> (236.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m60,554\u001b[0m (236.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">60,554</span> (236.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m60,554\u001b[0m (236.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.6573 - loss: 0.9777 - val_accuracy: 0.8294 - val_loss: 0.4805\n",
      "Epoch 2/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.8250 - loss: 0.4822 - val_accuracy: 0.8407 - val_loss: 0.4358\n",
      "Epoch 3/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.8535 - loss: 0.4036 - val_accuracy: 0.8602 - val_loss: 0.3858\n",
      "Epoch 4/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.8672 - loss: 0.3640 - val_accuracy: 0.8626 - val_loss: 0.3756\n",
      "Epoch 5/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.8783 - loss: 0.3306 - val_accuracy: 0.8720 - val_loss: 0.3481\n",
      "Epoch 6/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.8825 - loss: 0.3189 - val_accuracy: 0.8793 - val_loss: 0.3329\n",
      "Epoch 7/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.8935 - loss: 0.2910 - val_accuracy: 0.8783 - val_loss: 0.3343\n",
      "Epoch 8/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.8963 - loss: 0.2814 - val_accuracy: 0.8804 - val_loss: 0.3288\n",
      "Epoch 9/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9081 - loss: 0.2509 - val_accuracy: 0.8855 - val_loss: 0.3073\n",
      "Epoch 10/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.9158 - loss: 0.2332 - val_accuracy: 0.8784 - val_loss: 0.3295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8758 - loss: 0.3586\n",
      "Test Accuracy: 87.36%\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "import pickle\n",
    "\n",
    "# Load the preprocessed data from the pickle file\n",
    "with open('fashion_mnist_preprocessed.pkl', 'rb') as f:\n",
    "    x_train, y_train, x_test, y_test = pickle.load(f)\n",
    "\n",
    "# Build the Simple CNN model\n",
    "model = Sequential()\n",
    "\n",
    "# Convolutional Layer 1\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Convolutional Layer 2\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Optional: Convolutional Layer 3\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Flatten the output\n",
    "model.add(Flatten())\n",
    "\n",
    "# Dense Layer 1\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "# Output Layer (10 classes for Fashion MNIST)\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train, epochs=10, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Save the trained model for later use\n",
    "model.save('simple_cnn_fashion_mnist.h5')\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f\"Test Accuracy: {test_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7667131d-11b7-47e3-92ad-9c76b5e00c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step\n",
      "Predicted class: Shirt\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Fashion MNIST class names\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('simple_cnn_fashion_mnist.h5')\n",
    "\n",
    "# Function to preprocess and predict the class of an image\n",
    "def preprocess_and_predict(image_path):\n",
    "    # Load the image and resize to 28x28 (Fashion MNIST standard size)\n",
    "    img = Image.open(image_path).convert('L').resize((28, 28))  # Convert to grayscale\n",
    "\n",
    "    # Display the image\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(\"Uploaded Image\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    # Convert image to numpy array and scale pixel values\n",
    "    img_array = np.array(img).astype('float32') / 255.0\n",
    "    \n",
    "    # Reshape to match model input shape (batch_size, height, width, channels)\n",
    "    img_array = img_array.reshape(1, 28, 28, 1)\n",
    "    \n",
    "    # Predict the class of the image\n",
    "    prediction = model.predict(img_array)\n",
    "    \n",
    "    # Get the index of the class with the highest confidence\n",
    "    predicted_class = np.argmax(prediction)\n",
    "    \n",
    "    # Return the predicted class name\n",
    "    return class_names[predicted_class]\n",
    "\n",
    "# Example usage: Upload an image (specify the image path here)\n",
    "image_path = r'C:\\Users\\rahub\\OneDrive\\Desktop\\test.webp'\n",
    "predicted_label = preprocess_and_predict(image_path)\n",
    "print(f\"Predicted class: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2562af5-d434-4ab6-afd2-e49808e7e5fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
